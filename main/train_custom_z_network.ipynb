{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78068167-8013-4178-809c-17f03945cec6",
   "metadata": {},
   "source": [
    "# IMPORTS DE LIBRAIRIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e3a4a-d44a-4356-bbed-bcdb765690ef",
   "metadata": {},
   "source": [
    "Nous écrivons dans la cellule suivante sur quelle(s) GPU nous souhaitons exécuter le code.  \n",
    "Cependant, le code utilisé ne supporte pas encore le multi GPU pour l'entraînement.  Pour spécifier plusieurs GPU, séparer leur id d'une virgule.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e9a9c-e0a0-4c5a-98cf-ca20d6617c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,3\"\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d02d31-7e3d-4566-9071-4187b20ae959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "print(\"torch version           : \", torch.__version__)\n",
    "print(\"torch cuda version      : \", torch.version.cuda)\n",
    "print(\"torch.cuda.is_available : \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5074e79-12d1-42c5-8f4a-58e841e8c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "print(\"detectron2 version : \", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985c4d5-3a69-42a1-a665-161c9ca823bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor, DefaultTrainer, launch\n",
    "from detectron2.config import get_cfg, get_stack_cell_config\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.common import DatasetFromList\n",
    "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data.datasets import get_dicts\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66562ae0-d3bd-442b-ae9d-c22e73fce396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json, cv2, random, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38f312-40e8-47fa-b202-89b197e899fe",
   "metadata": {},
   "source": [
    "Le logger permet d'afficher des informations importantes tout au long de l'exécution des cellules.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0190a3c-2391-446d-bb3b-e11657502818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27893f8-47fe-406a-b4a8-3eef16e0a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imBGRshow(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b780c-40af-4be5-a429-a56b28ea861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imRGBshow(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a707c0c-385d-46f7-82a7-21388eb87864",
   "metadata": {},
   "source": [
    "# REGISTER LES IMAGES\n",
    "## /!\\ CHANGE THE DATA PATH ACCORDINGLY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925a8ac-e943-42aa-bc9c-d79f544ced5b",
   "metadata": {},
   "source": [
    "NB : Les classes sont les suivantes :\n",
    "- 0 : Cellule intacte et nette   (Intact_Sharp)\n",
    "- 1 : Cellule intacte et floue   (Intact_Blurry)\n",
    "- 2 : Cellule explosée et nette  (Broken_Sharp)\n",
    "- 3 : Cellule explosée et floue  (Broken_Blurry)\n",
    "\n",
    "Pour seulement considérer les cellules nettes, utiliser :\n",
    "classes = {'Intact_Sharp':0, 'Broken_Sharp':2}\n",
    "\n",
    "Pour considérer tous les types de cellules, utiliser :\n",
    "classes = {'Intact_Sharp':0,'Intact_Blurry':1,'Broken_Sharp':2,'Broken_Blurry':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4d5e4-8a23-4ab7-b2e0-bf28ec49c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'Intact_Sharp':0, 'Broken_Sharp':2}\n",
    "#classes = {'Intact_Sharp':0,'Intact_Blurry':1,'Broken_Sharp':2,'Broken_Blurry':3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415477bb-1ce2-453c-9c8d-e7f9904c1d24",
   "metadata": {},
   "source": [
    "# DATASET\n",
    "\n",
    "Les noms de fichiers sont enregistrées au format suivant : TxxPyyFzz avec xx le puceron, yy le cluster, et zz le positionnement de l'image des la pile.\n",
    "Les images sont au format png. Elles sont de taille 400x300. Chaque image possède un fichier json associé ayant le même nom. Dans celui-ci sont enregistrés des données permettant l'identification de l'image, ainsi que les positions et tailles des boîtes englobantes, les classes, ainsi que les différentes segmentations au format polygon.\n",
    "\n",
    "## AUGMENTATION DES DONNÉES\n",
    "L'augmentation des données a été réalisée en amont de l'algorithme. Les données augmentées se trouvent d'ores et déjà dans les dossiers spécifiés au dessus. Seules les augmentations en netteté et en cisaillement n'ont pas été implémentées. En effet, la première cause une netteté de toutes les cellules et ne permettra pas au model d'apprendre la différence entre une cellule nette et une cellule floue. Le cisaillement cause quant à lui une déformation trop importante de la membrane extérieure des bactériocytes, rendant très difficile une différenciation des cellules intactes et des cellules explosées.\n",
    "\n",
    "35 augmentations différentes ont été implémentées. Le réseau verra donc 36 versions des différentes piles. Les données sont séparées en 5 (voir partie organisation ci-dessous).\n",
    "- 0 : 15444 images => 1404 piles (depuis 39 piles)\n",
    "- 1 : 15411 images => 1401 piles (depuis 39 piles)\n",
    "- 2 : 15015 images => 1365 piles (depuis 39 piles)\n",
    "- 3 : 15015 images => 1365 piles (depuis 39 piles)\n",
    "- 4 : 14619 images => 1329 piles (depuis 38 piles)\n",
    "\n",
    "La partie 4 possède 2 défauts majeurs qu'il convient de prendre en compte : la pile Augmented1T9P20 a une image où la moitié est grise. Il convient donc de supprimer cette pile manuellement. Les piles T10P1Fxx ne possèdent pas 11 images. Celles-ci sont écartées automatiquement par l'algorithme lors du chargement des données. Des piles avec un plus grand nombre d'images que celui attendu seraient chargées jusqu'à leur 11ème image seulement.  \n",
    "Une fois la pile Augmented1T9P20 supprimée manuellement, il reste 14864 images, dont seulement 14619 seront exploitables comme une pile entière doit être écartée, avec toute ses augmentations. C'est cette pile qui amène le nombre de pile à 38 et non 39 comme les autres parties du dataset.  \n",
    "  \n",
    "Des défauts moins importants subsitent : nous remarquons que même si les images sont obtenues à partir du même nombre de piles initiallement, il n'y a pas le même nombre d'image dans chaque partie. Certaines augmentations n'ont pas été réalisées sur certaines piles. \n",
    "\n",
    "## ORGANISATION\n",
    "Le dataset est séparé en 3 jeux de données : \n",
    "- 60%    => Entraînement\n",
    "- 20%    => Validation\n",
    "- 20%    => Test  \n",
    "  \n",
    "Les données doivent être rangées dans la structure suivante de fichiers. La variable data_path définie dans la variable suivante doit indiquer l'emplacement du dossier Cross-val.  \n",
    "/!\\ ATTENTION, ce chemin est à adapter.  \n",
    "└── Cross-val  \n",
    "&emsp;&emsp;&emsp;   ├── Xval0  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   ├── Xval1  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   ├── Xval2  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   ├── Xval3  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   └── Xval4  \n",
    "&emsp;&emsp;&emsp; &emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; &emsp;&emsp;   └── labels  \n",
    "\n",
    "## VALIDATION CROISEE\n",
    "Comme son nom l'indique, cette séparation est réalisée afin de pouvoir faire de la validation croisée (cross-validation). Pour des raisons écologiques et de durée d'entraînement, nous n'avons pas tiré profit de cette possibilité, mais il est important de noter qu'elle est facilement implémetable au besoin.  \n",
    "Un indice indique quelles parties du dataset seront associées avec quel jeu de données (entraînement, validation ou test). Pour réaliser de la validation croisée, il faudra réaliser l'entrainement pour des indices variant de 0 à 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d51a4f-e54f-4567-816e-4fe855f97c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/projects/INSA-Image/B01/Data/'\n",
    "cross_val_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b5e97-ef06-4482-bd1a-324ffdee78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modes must have the correct string associated in order to perform the proper operation\n",
    "mode_train = 'train'\n",
    "mode_valid = 'val'\n",
    "mode_test  = 'test'\n",
    "\n",
    "# By default in our architecture. To use custom names, an override of these names must happen during the configuration (see next section)\n",
    "dataset_name_train = 'train'\n",
    "dataset_name_valid = 'val'\n",
    "dataset_name_test  = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376f531-5abc-446a-bc39-f2d6f3177121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the datasets\n",
    "DatasetCatalog.register(dataset_name_train, lambda: get_dicts(data_path, mode_train, cross_val_idx, classes, dataset_name_train))\n",
    "DatasetCatalog.register(dataset_name_valid, lambda: get_dicts(data_path, mode_valid, cross_val_idx, classes, dataset_name_valid))\n",
    "DatasetCatalog.register(dataset_name_test,  lambda: get_dicts(data_path, mode_test,  cross_val_idx, classes, dataset_name_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c5b2f-b015-4648-9b03-67990b0e6469",
   "metadata": {},
   "source": [
    "# AFFICHAGE DE QUELQUES IMAGES AVEC LEUR SEGMENTATION MANUELLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712503ad-59c0-4e77-8a58-97258d28052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metadata = MetadataCatalog.get(dataset_name_valid)\n",
    "valid_dataset_dicts = DatasetCatalog.get(dataset_name_valid)\n",
    "valid_dataset = DatasetFromList(valid_dataset_dicts, True, 11, serialize=False)\n",
    "# Attention : si le dataset est serialized alors on ne pourra pas accéder correctement à la liste de tous les dictionnaires de la pile.\n",
    "# La serialisation (en pickle ici) est cependant très intéressante pour stocker et transmettre des données, ce qui est utile dans d'autres parties du programme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffda710-424f-4787-a5b6-ac7d72fb80a6",
   "metadata": {},
   "source": [
    "La cellule suivante permet par défaut d'afficher N piles ainsi que leur segmentation. Ces N piles sont tirées au hasard dans le dataset de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320b11e-a855-48c5-bbc6-1cf8d0f7aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize N random stacks\n",
    "N = 1\n",
    "stack = [None] * 11\n",
    "for data in random.sample(valid_dataset._lst, N):\n",
    "    for z in range (11):\n",
    "        stack[z] = cv2.imread(data[z][\"file_name\"])\n",
    "        visualizer = Visualizer(stack[z][:, :, ::-1], metadata=valid_metadata, scale=1)\n",
    "        out = visualizer.draw_dataset_dict(data[z])\n",
    "        imRGBshow(out.get_image())\n",
    "        # print(data[z][\"file_name\"]) # Print the file path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4adfd8-aab8-4565-941c-04c7dcd716ad",
   "metadata": {},
   "source": [
    "# ENTRAINEMENT\n",
    "\n",
    "Detectron2 ne permet pas de réaliser de validation en même temps que l'entraînement. Pour pouvoir éviter le sur entraînement, nous allons réaliser la méthode suivante :\n",
    "1. Réaliser la configuration\n",
    "2. Entrainer le modèle en enregistrant ses poids à intervalles réguliers\n",
    "3. Pour tous les poids enregistrés, évaluer les performances du réseau afin de trouver les meilleurs poids\n",
    "4. Enfin, pour les poids sélectionnés, nous allons réaliser l'évaluation de notre réseau entraîné.\n",
    "\n",
    "\n",
    "### ENTRAINEMENT MULTI-GPU\n",
    "L'entraînement multi-GPU produit une erreur dans ce notebook. Cependant, il est bien possible d'entraîner le réseau en multi-GPU. Pour cela, il faut utiliser la commande suivante dans le terminal, en étant dans le dossier dans lequel le git est cloné, avec un environnement adéquat :  \n",
    "OMP_NUM_THREADS=1 python tools/train_net.py \\\n",
    "    --config-file configs/Segmentation-Z/mask_rcnn_z_50.yaml \\\n",
    "    --num-gpus 2 \\\n",
    "    --dist-url \"auto\" \\\n",
    "    OUTPUT_DIR training_dir  \n",
    "Le bug doit donc venir de la manière dont Jupyter interagit avec le processus de spawning utilisé pour réunir les informations venant des différentes GPU. La suite de ce notebook explique donc les idées derrière le code du fichier train_net.py. Il faudra laisser la variable num_gpus dans ce notebook à 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82db0f8-b893-45e5-85ff-7d4f70f5ebf4",
   "metadata": {},
   "source": [
    "## CONFIGURATION DU RESEAU ET DES PARAMETRES D'ENTRAINEMENT\n",
    "Cette configuration est similaire que pour des utilisations de detectron2 normales.  \n",
    "Il faut cependant changer les configurations par défaut suivantes :\n",
    "- Architecture\n",
    "- Input chargé par le dataloader\n",
    "- Nombre de classes\n",
    "- Poids du réseaux et couches figées\n",
    "- Solveur avec enregistrement des poids\n",
    "- Nombre de GPU (seulement 1 GPU est possible pour l'instant)\n",
    "- Automatic Mixed Precision (debug en cours)\n",
    "  \n",
    "NB : Selon la configuration donnée par la fonction get_stack_cell_config, les images seront redimensionnées de 300x400 à 480x640. Cela permet d'être à la même taille que les images du challenge COCO. C'est aussi une taille divisible par le downsampling (sous-echantillonnage) du resnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa4981-7c80-44af-bf7d-1bb8d7421476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config_architecture_file = '../configs/Segmentation-Z/mask_rcnn_z_50.yaml'\n",
    "config_architecture_file = '../configs/Segmentation-Z/mask_rcnn_3d.yaml'\n",
    "\n",
    "# Pour sauvegarder des données d'entrapinement, notamment les poids du réseau entraîné\n",
    "output_directory = \"/tmp/TEST/outputs/0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f0c99-0780-4b82-af2f-faf8e0d5a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 1      # torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c80c2-36fc-4608-b3b1-73a8cf3f8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de base présente dans ../detectron2/config/defaults.py\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Configuration de l'architecture (depuis le fichier de configuration défini dans config_architecture_file)\n",
    "cfg.merge_from_file(config_architecture_file)\n",
    "cfg.MODEL.RESNETS.DEPTH = 18                                 # Configuration of the depth of the resnet network, default to 50, for lighter models, use 18\n",
    "cfg.MODEL.RESNETS.RES2_OUT_CHANNELS = {18:64, 32:64, 50:256, 101:256, 152:256}[cfg.MODEL.RESNETS.DEPTH]\n",
    "\n",
    "# Configuration de l'input : pile. Pour d'autres configuration de pile, il faut soit override les paramètres particuliers configurés dans la fonction, soit écrire une autre fonction.\n",
    "cfg = get_stack_cell_config(cfg)\n",
    "\n",
    "# Configuration du nombre de classes\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\n",
    "\n",
    "# Configuration des poids du réseau et des couches figées\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 0      # 0  => aucune couche figée\n",
    "cfg.MODEL.WEIGHTS = \"\"                # \"\" => pas de poids préchargés, ils seront tirés au hasard\n",
    "\n",
    "# Configuration du solveur\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1          # Attention à la taille de la mémoire dont dispose la GPU, doit aussi être un multiple du nombre de GPU\n",
    "if (cfg.SOLVER.IMS_PER_BATCH % num_gpus != 0):    # Pour être sûr d'être divisible par le nombre de GPU\n",
    "    cfg.SOLVER.IMS_PER_BATCH = (cfg.SOLVER.IMS_PER_BATCH // num_gpus) * num_gpus\n",
    "cfg.SOLVER.MAX_ITER = 100      # Pour test, sinon, remettre 10000\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = cfg.SOLVER.MAX_ITER // 20\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "# Configuration du dossier pour sauvegarder les sorties de l'algorithme\n",
    "cfg.OUTPUT_DIR = output_directory\n",
    "\n",
    "# Configuration multi GPU\n",
    "cfg.SOLVER.REFERENCE_WORLD_SIZE = num_gpus\n",
    "\n",
    "# Configuration automatic mixed precision (False => float32, True => float16)\n",
    "cfg.MODEL.USE_AMP = False\n",
    "\n",
    "## Configuration de l'évaluation en même temps que les poids sont enrégistrés\n",
    "#cfg.TEST.EVAL_PERIOD = cfg.SOLVER.CHECKPOINT_PERIOD\n",
    "# MAIS LE FAIT SUR LE DATASET TEST AU LIEU DE VALID...\n",
    "\n",
    "# La configuration ne pourra plus être modifiée :\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c0293-a281-4c19-b2c5-43f450cbb2d6",
   "metadata": {},
   "source": [
    "## ENTRAINEMENT DU RESEAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd307d-f2be-4995-9f96-cbaaaa4da87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train():\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    # False to begin training from scratch, \n",
    "    # True, takes the specified weights in config, or begin from scratch if no weight specified\n",
    "    # In our case, since we didn't specify weights, trianing will begin from scratch\n",
    "    return trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    launch(my_train, num_gpus_per_machine=num_gpus, num_machines=1, dist_url=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df402483-b216-40a9-a3bb-ea7eaf8a7e34",
   "metadata": {},
   "source": [
    "### /!\\ \n",
    "Il faut bien ré écrire le chemin présent dans output_directory entre les guillemets afin d'afficher les courbes. Il est normal que les losses soient 0 pour les images proches des extrémités car elles ne possèdent en général aucune cellule nette et en ne prédisant rien, elles ne se trompent jamais ou presque. \n",
    "  \n",
    "Ceci est une limitation du réseau, que nous attendions dans le cas de convolutions 2D. Pour le backbone réalisant des convolutions 3D, toutes les images sont traitées de manière plus similaire et cette limitation est moins importantes.  \n",
    "  \n",
    "Pour les backbones réalisant des convolutions 2D, nous pourrions imaginer mélanger les images au sein d'une même pile afin que l'apprentissage se réalise aussi sur les images des bords. Cependant, quand l'information sera mélangée au sein du réseau, nous perdons l'organisation spatiale réelle des images, ce qui perturbera l'attention entre features de chaque image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c3cc6-b780-47dc-8709-55ca03fe06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"/tmp/TEST/outputs/3D\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6362567-d014-47a2-879c-3f057bad8c1f",
   "metadata": {},
   "source": [
    "## VALIDATION DES MEILLEURS POIDS DU RESEAU\n",
    "Pour tous les poids enregistrés, nous évaluons les performances du réseau avec le dataset de validation afin de trouver les meilleurs poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ef172-acc9-458c-9b07-a3f69d104381",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.defrost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34964c1f-8ad3-446e-b3e5-23c0958ec109",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights_paths = sorted(glob.glob(os.path.join(output_directory, 'model_*.pth')))\n",
    "metrics = [None] * len(all_weights_paths)\n",
    "for (i, weights_path) in zip(range(len(all_weights_paths)), all_weights_paths):\n",
    "    print(weights_path)\n",
    "    cfg.MODEL.WEIGHTS = weights_path\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    valid_evaluator = COCOEvaluator(dataset_name_valid, cfg, True, output_dir=output_directory)\n",
    "    valid_loader = build_detection_test_loader(cfg, dataset_name_valid)\n",
    "    # Faire un truc qui garde en mémoire tout et prenne le meilleur\n",
    "    metrics[i] = inference_on_dataset(predictor.model, valid_loader, valid_evaluator, cfg.DATALOADER.IS_STACK)\n",
    "    #print(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ef916-5961-4474-91a7-19daa79ce843",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/tmp/TEST/outputs/3D/\"\n",
    "#output_directory = output_directory\n",
    "best_weights = \"model_final.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2412fc2-06d6-43a8-aba5-b3a58a438cdc",
   "metadata": {},
   "source": [
    "## EVALUATION DU MODELE\n",
    "Pour les poids trouvés précédemment, nous évaluons notre modèle sur le dataset de test.  \n",
    "Cette évaluation ne peut se faire avec le dataset précédent car c'est celui qui a servi à la sélection des poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b331c73-b56b-49b6-a3af-0efe74ec2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(output_directory, best_weights)\n",
    "# OR cfg.MODEL.WEIGHTS = best_weights\n",
    "# IF best_weights has the whole paths\n",
    "# Training on Detectron2 with a Validation set, and plot loss on it to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b7138-764a-4a41-9226-b1764f0ceb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = COCOEvaluator(dataset_name_test, cfg, True, output_dir=output_directory)\n",
    "test_loader = build_detection_test_loader(cfg, dataset_name_test)\n",
    "test_metrics = inference_on_dataset(predictor.model, test_loader, test_evaluator, cfg.DATALOADER.IS_STACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26ec3d-6ea4-4d1e-acef-b1aa65d2bdf4",
   "metadata": {},
   "source": [
    "# VISUALISATION SUR UNE STACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf0f9e-3fc9-4ba6-a643-7bc9d3957612",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = MetadataCatalog.get(dataset_name_test)\n",
    "test_dataset_dicts = DatasetCatalog.get(dataset_name_test)\n",
    "test_dataset = DatasetFromList(test_dataset_dicts, cfg.DATALOADER.IS_STACK, cfg.INPUT.STACK_SIZE, serialize=False)\n",
    "# Attention : si le dataset est serialized alors on ne pourra pas accéder correctement à la liste de tous les dictionnaires de la pile.\n",
    "# La serialisation (en pickle ici) est cependant très intéressante pour stocker et transmettre des données, ce qui est utile dans d'autres parties du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18899509-0ea4-438d-9c35-e8c7f5b64fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6c594-7612-4a34-891a-bde8d6e83117",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "stack = [None] * cfg.INPUT.STACK_SIZE\n",
    "out   = [None] * cfg.INPUT.STACK_SIZE\n",
    "for data in random.sample(test_dataset._lst, N):\n",
    "    for z in range(cfg.INPUT.STACK_SIZE):\n",
    "        stack[z] = cv2.imread(data[z][\"file_name\"])\n",
    "    outputs = predictor(stack)\n",
    "    \n",
    "    for z in range(cfg.INPUT.STACK_SIZE):\n",
    "        visualizer = Visualizer(stack[z][:, :, ::-1], metadata=test_metadata, scale=1)\n",
    "        visualizer_GT = Visualizer(stack[z][:, :, ::-1], metadata=test_metadata, scale=1)\n",
    "        out[z] = visualizer.draw_instance_predictions(outputs[z][\"instances\"].to(\"cpu\"))\n",
    "        out_GT = visualizer_GT.draw_dataset_dict(data[z])\n",
    "        print(z)\n",
    "        print(\"Ground Truth\")\n",
    "        imRGBshow(out_GT.get_image())\n",
    "        print(\"Predicted\")\n",
    "        imRGBshow(out[z].get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf0a61-f030-4cc8-8de1-dcfc791a8be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
