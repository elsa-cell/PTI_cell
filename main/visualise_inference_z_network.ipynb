{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78068167-8013-4178-809c-17f03945cec6",
   "metadata": {},
   "source": [
    "# IMPORTS DE LIBRAIRIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e3a4a-d44a-4356-bbed-bcdb765690ef",
   "metadata": {},
   "source": [
    "Nous écrivons dans la cellule suivante sur quelle(s) GPU nous souhaitons exécuter le code. Pour spécifier plusieurs GPU, séparer leur id d'une virgule.    \n",
    "Cependant, le code utilisé ne supporte pas encore le multi GPU.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e9a9c-e0a0-4c5a-98cf-ca20d6617c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d02d31-7e3d-4566-9071-4187b20ae959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "print(\"torch version           : \", torch.__version__)\n",
    "print(\"torch cuda version      : \", torch.version.cuda)\n",
    "print(\"torch.cuda.is_available : \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5074e79-12d1-42c5-8f4a-58e841e8c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "print(\"detectron2 version : \", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985c4d5-3a69-42a1-a665-161c9ca823bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor, DefaultTrainer, launch\n",
    "from detectron2.config import get_cfg, get_stack_cell_config\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.common import DatasetFromList\n",
    "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data.datasets import get_dicts\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66562ae0-d3bd-442b-ae9d-c22e73fce396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json, cv2, random, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38f312-40e8-47fa-b202-89b197e899fe",
   "metadata": {},
   "source": [
    "Le logger permet d'afficher des informations importantes tout au long de l'exécution des cellules.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0190a3c-2391-446d-bb3b-e11657502818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27893f8-47fe-406a-b4a8-3eef16e0a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imBGRshow(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b780c-40af-4be5-a429-a56b28ea861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imRGBshow(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a073d6ac",
   "metadata": {},
   "source": [
    "### VISUALISATION DES COURBES D'ENTRAINEMENT\n",
    "Présent dans ce notebook pour ne pas avoir à chercher la cellule dans le notebook train_custom_z_network.ipynb  \n",
    "Bien penser à adapter *--logdir* au chemin où les résultats de l'entraînement ont été stockés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"/tmp/TEST/outputs/3D_50_layers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a707c0c-385d-46f7-82a7-21388eb87864",
   "metadata": {},
   "source": [
    "# REGISTER LES IMAGES\n",
    "## /!\\ CHANGE THE DATA PATH ACCORDINGLY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925a8ac-e943-42aa-bc9c-d79f544ced5b",
   "metadata": {},
   "source": [
    "NB : Les classes sont les suivantes :\n",
    "- 0 : Cellule intacte et nette   (Intact_Sharp)\n",
    "- 1 : Cellule intacte et floue   (Intact_Blurry)\n",
    "- 2 : Cellule explosée et nette  (Broken_Sharp)\n",
    "- 3 : Cellule explosée et floue  (Broken_Blurry)\n",
    "\n",
    "Pour seulement considérer les cellules nettes, utiliser :\n",
    "classes = {'Intact_Sharp':0, 'Broken_Sharp':2}\n",
    "\n",
    "Pour considérer tous les types de cellules, utiliser :\n",
    "classes = {'Intact_Sharp':0,'Intact_Blurry':1,'Broken_Sharp':2,'Broken_Blurry':3}  \n",
    "  \n",
    "NB: Les entraînements ont été faits avec seulement les cellules nettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4d5e4-8a23-4ab7-b2e0-bf28ec49c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'Intact_Sharp':0, 'Broken_Sharp':2}\n",
    "#classes = {'Intact_Sharp':0,'Intact_Blurry':1,'Broken_Sharp':2,'Broken_Blurry':3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415477bb-1ce2-453c-9c8d-e7f9904c1d24",
   "metadata": {},
   "source": [
    "# DATASET\n",
    "\n",
    "Les noms de fichiers sont enregistrées au format suivant : TxxPyyFzz avec xx le puceron, yy le cluster, et zz le positionnement de l'image des la pile.\n",
    "Les images sont au format png. Elles sont de taille 400x300. Chaque image possède un fichier json associé ayant le même nom. Dans celui-ci sont enregistrés des données permettant l'identification de l'image, ainsi que les positions et tailles des boîtes englobantes, les classes, ainsi que les différentes segmentations au format polygon.\n",
    "\n",
    "## AUGMENTATION DES DONNÉES\n",
    "L'augmentation des données a été réalisée en amont de l'algorithme. Les données augmentées se trouvent d'ores et déjà dans les dossiers spécifiés au dessus. Seules les augmentations en netteté et en cisaillement n'ont pas été implémentées. En effet, la première cause une netteté de toutes les cellules et ne permettra pas au model d'apprendre la différence entre une cellule nette et une cellule floue. Le cisaillement cause quant à lui une déformation trop importante de la membrane extérieure des bactériocytes, rendant très difficile une différenciation des cellules intactes et des cellules explosées.\n",
    "\n",
    "35 augmentations différentes ont été implémentées. Le réseau verra donc 36 versions des différentes piles. Les données sont séparées en 5 (voir partie organisation ci-dessous).\n",
    "- 0 : 15444 images => 1404 piles (depuis 39 piles)\n",
    "- 1 : 15411 images => 1401 piles (depuis 39 piles)\n",
    "- 2 : 15015 images => 1365 piles (depuis 39 piles)\n",
    "- 3 : 15015 images => 1365 piles (depuis 39 piles)\n",
    "- 4 : 14619 images => 1329 piles (depuis 38 piles)\n",
    "\n",
    "La partie 4 possède 2 défauts majeurs qu'il convient de prendre en compte : la pile Augmented1T9P20 a une image où la moitié est grise. Il convient donc de supprimer cette pile manuellement. Les piles T10P1Fxx ne possèdent pas 11 images. Celles-ci sont écartées automatiquement par l'algorithme lors du chargement des données. Des piles avec un plus grand nombre d'images que celui attendu seraient chargées jusqu'à leur 11ème image seulement.  \n",
    "Une fois la pile Augmented1T9P20 supprimée manuellement, il reste 14864 images, dont seulement 14619 seront exploitables comme une pile entière doit être écartée, avec toute ses augmentations. C'est cette pile qui amène le nombre de pile à 38 et non 39 comme les autres parties du dataset.  \n",
    "  \n",
    "Des défauts moins importants subsitent : nous remarquons que même si les images sont obtenues à partir du même nombre de piles initiallement, il n'y a pas le même nombre d'image dans chaque partie. Certaines augmentations n'ont pas été réalisées sur certaines piles. \n",
    "\n",
    "## ORGANISATION\n",
    "Le dataset est séparé en 3 jeux de données : \n",
    "- 60%    => Entraînement\n",
    "- 20%    => Validation\n",
    "- 20%    => Test  \n",
    "  \n",
    "Les données doivent être rangées dans la structure suivante de fichiers. La variable data_path définie dans la variable suivante doit indiquer l'emplacement du dossier Cross-val.  \n",
    "/!\\ ATTENTION, ce chemin est à adapter.  \n",
    "└── Cross-val  \n",
    "&emsp;&emsp;&emsp;   ├── Xval0  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   ├── Xval1  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   ├── Xval2  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   ├── Xval3  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; |&emsp;&emsp;   └── labels  \n",
    "&emsp;&emsp;&emsp;   └── Xval4  \n",
    "&emsp;&emsp;&emsp; &emsp;&emsp;   ├── images  \n",
    "&emsp;&emsp;&emsp; &emsp;&emsp;   └── labels  \n",
    "\n",
    "## VALIDATION CROISEE\n",
    "Comme son nom l'indique, cette séparation est réalisée afin de pouvoir faire de la validation croisée (cross-validation). Pour des raisons écologiques et de durée d'entraînement, nous n'avons pas tiré profit de cette possibilité, mais il est important de noter qu'elle est facilement implémetable au besoin.  \n",
    "Un indice indique quelles parties du dataset seront associées avec quel jeu de données (entraînement, validation ou test). Pour réaliser de la validation croisée, il faudra réaliser l'entrainement pour des indices variant de 0 à 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d51a4f-e54f-4567-816e-4fe855f97c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/projects/INSA-Image/B01/Data/'\n",
    "cross_val_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b5e97-ef06-4482-bd1a-324ffdee78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modes must have the correct string associated in order to perform the proper operation\n",
    "mode_test  = 'test'\n",
    "dataset_name_test  = 'val'      # Pour correspondre à faire l'inférence et pas le training selon la confiuration . La partie du dataset loadée est bien définie par le mode_tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376f531-5abc-446a-bc39-f2d6f3177121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the datasets\n",
    "DatasetCatalog.register(dataset_name_test,  lambda: get_dicts(data_path, mode_test,  cross_val_idx, classes, dataset_name_test))\n",
    "# Set the evaluator to the coco evaluator\n",
    "MetadataCatalog.get('val').set(evaluator_type=\"coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50332ff6",
   "metadata": {},
   "source": [
    "# CHARGEMENT DE LA CONFIGURATION EXISTANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0135a4",
   "metadata": {},
   "source": [
    "Les meilleurs poids sont:\n",
    "- BACKBONE 2D, 18 LAYERS (10 000 iterations) : model_0000499.pth\n",
    "- BACKBONE 2D, 50 LAYERS (11 000 iterations) : model_0009999.pth\n",
    "- BACKBONE 3D, 18 LAYERS (10 000 iterations) : model_0000499.pth\n",
    "- BACKBONE 3D, 50 LAYERS (30 000 iterations) : model_0000499.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin jusqu'aux fichiers contenant les poids du réseau et sa configuration\n",
    "path_to_weights_and_config = \"/tmp/TEST/outputs/test/\"\n",
    "# Fichier de poids à utiliser\n",
    "weight_file = \"model_final.pth\"\n",
    "# Chemin dans lequel sauvegarder les images segmentées par l'algorithme et la vérité terrain\n",
    "output_directory = \"/tmp/TEST/outputs/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(os.path.join(path_to_weights_and_config, \"config.yaml\"))    # Chargement de la configuration existante\n",
    "\n",
    "# Adaptation pour l'inférence\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1                    # Attention, doit être réadapté, surtout si l'entraînement était en multigpu\n",
    "cfg.MODEL.WEIGHTS = os.path.join(path_to_weights_and_config, weight_file)\n",
    "cfg.REFERENCE_WORLD_SIZE = 1                    # Doit être au nombre de gpu * nombre de machine, pour le jupyter notebook, à 1 comme fonctionne à 1 GPU sur 1 machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce9a70",
   "metadata": {},
   "source": [
    "# VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa4981-7c80-44af-bf7d-1bb8d7421476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du predicteur\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94368a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère le metadata du dataset, une liste de ses dictionnaires, et enfin le dataset lui-même, en format torch, qui est nécessaire pour faire la prédiction sur la pile\n",
    "test_metadata = MetadataCatalog.get(dataset_name_test)\n",
    "test_dataset_dicts = DatasetCatalog.get(dataset_name_test)\n",
    "test_dataset = DatasetFromList(test_dataset_dicts, cfg.DATALOADER.IS_STACK, cfg.INPUT.STACK_SIZE, serialize=False)\n",
    "# Attention : si le dataset est serialized alors on ne pourra pas accéder correctement à la liste de tous les dictionnaires de la pile.\n",
    "# La serialisation (en pickle ici) est cependant très intéressante pour stocker et transmettre des données, ce qui est utile dans d'autres parties du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de N piles choisies au hasard dans le dataset\n",
    "N = 1\n",
    "stack = [None] * cfg.INPUT.STACK_SIZE\n",
    "out   = [None] * cfg.INPUT.STACK_SIZE\n",
    "for data in random.sample(test_dataset._lst, N):\n",
    "\n",
    "    # Construction de la pile d'image à partir du dataset\n",
    "    for z in range(cfg.INPUT.STACK_SIZE):\n",
    "        stack[z] = cv2.imread(data[z][\"file_name\"])\n",
    "\n",
    "    # Prédiction sur la pile\n",
    "    outputs = predictor(stack)\n",
    "\n",
    "    # Affichage\n",
    "    for z in range(cfg.INPUT.STACK_SIZE):\n",
    "        print(z)\n",
    "\n",
    "        visualizer_GT = Visualizer(stack[z][:, :, ::-1], metadata=test_metadata, scale=1)       # Construit le visualiser\n",
    "        out_GT = visualizer_GT.draw_dataset_dict(data[z])                                       # Dessine les annotations sur l'image\n",
    "        print(\"Ground Truth\")\n",
    "        imRGBshow(out_GT.get_image())                                                           # Display l'image\n",
    "        cv2.imwrite(os.path.join(output_directory,  f\"GTimage_{z}.jpg\"), cv2.cvtColor(out_GT.get_image(), cv2.COLOR_RGB2BGR))    # Enregistre l'image\n",
    "\n",
    "        visualizer = Visualizer(stack[z][:, :, ::-1], metadata=test_metadata, scale=1)\n",
    "        out[z] = visualizer.draw_instance_predictions(outputs[z][\"instances\"].to(\"cpu\"))\n",
    "        print(\"Predicted\")\n",
    "        imRGBshow(out[z].get_image())\n",
    "        cv2.imwrite(os.path.join(output_directory,  f\"DTimage_{z}.jpg\"), cv2.cvtColor(out[z].get_image(), cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39d276-acd0-4822-81ea-ef5c5900005c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
